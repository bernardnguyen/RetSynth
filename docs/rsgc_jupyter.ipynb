{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RetSynth Software \n",
    "### RetSynth is a tool, developed with python, which identfies enzyme/reaction pairs that are required in a user specified microbial organisms to produce a target chemical compound. \n",
    "\n",
    "## Purpose\n",
    "### In the process of bioengineering a microbial organism, identifying reactions/enzymes to transform into an organism for optimal production of a target compound is extremely difficult due to the vast number of reactions/enzymes in numerous organisms that maybe suitable for optimal production.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in necessary libraries\n",
    "from __future__ import print_function\n",
    "\n",
    "from multiprocessing import Process\n",
    "import argparse\n",
    "\n",
    "from IPython.display import HTML\n",
    "\n",
    "try:\n",
    "    import pickle\n",
    "except:\n",
    "    import cPickle as pickle\n",
    "import os\n",
    "import re\n",
    "import glob\n",
    "import time\n",
    "import shutil\n",
    "import zipfile\n",
    "from sys import platform\n",
    "PATH = os.path.dirname(os.path.abspath('__file__'))\n",
    "\n",
    "def verbose_print(verbose, line):\n",
    "    if verbose:\n",
    "        print(line)\n",
    "\n",
    "def unzip_necessary_files_and_libraries():\n",
    "  '''Unzip Default Databases and indigo libraries'''\n",
    "  def unzip_folder(foldername):\n",
    "      if os.path.isdir(foldername) is False:\n",
    "        try:\n",
    "            zipref = zipfile.ZipFile(foldername+'.zip', 'r')\n",
    "            zipref.extractall('.')\n",
    "        except:\n",
    "            pass\n",
    "            # print(\"WARNING: No \"+foldername+\".zip\")\n",
    "  try: \n",
    "      unzip_folder(PATH+\"/ConstructedDatabases\")\n",
    "  except FileNotFoundError:\n",
    "      print(\"WARNING: No ConstructedDatabase\")\n",
    "\n",
    "  if platform == 'darwin':\n",
    "      unzip_folder(PATH+'/indigopython130_mac')\n",
    "\n",
    "  elif platform == \"linux\" or platform == \"linux2\":\n",
    "      unzip_folder(PATH+'/indigopython130_linux')\n",
    "\n",
    "  elif platform == \"win32\" or platform == \"win64\" or platform == \"cygwin\":\n",
    "      unzip_folder(PATH+'/indigopython130_win')\n",
    "\n",
    "unzip_necessary_files_and_libraries()\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from rsgc.Parser import read_startcompounds as rtsc\n",
    "from rsgc.Parser import read_targets as rt\n",
    "from rsgc.Parser import generate_output as go\n",
    "from rsgc.Parser import structure_similarity as ss\n",
    "from rsgc.Parser import generate_html as gh\n",
    "from rsgc.Visualization_chemdraw import reaction_files as rf\n",
    "from rsgc.Visualization_graphviz import SP_Graph_dot as spgd\n",
    "from rsgc.ShortestPath import extractinfo as ei\n",
    "from rsgc.ShortestPath import constraints as co\n",
    "from rsgc.ShortestPath import integerprogram_pulp as ip_pulp\n",
    "from rsgc.Database import initialize_database as init_db\n",
    "from rsgc.Database import build_modelseed as bms\n",
    "from rsgc.Database import build_metacyc_db as bmcdb\n",
    "from rsgc.Database import build_user_rxns_db as burdb\n",
    "from rsgc.Database import build_ATLAS_db as batlasdb\n",
    "from rsgc.Database import build_MINE_db as bminedb\n",
    "from rsgc.Database import build_KEGG_db as bkeggdb\n",
    "from rsgc.Database import build_SPRESI_db as bspresidb\n",
    "from rsgc.Database import query as Q\n",
    "from rsgc.Database import remove_duplicate_cpds as rdc\n",
    "from rsgc.FBA import build_model as bm\n",
    "from rsgc.FBA import optimize_target as ot\n",
    "from rsgc.FBA import compare_results as cr\n",
    "from rsgc.FBA import retrieve_producable_mets as rpm\n",
    "from rsgc.FBA import compareKO_results as crko\n",
    "from rsgc.GeneCompatibility.gc import gc_main as gc\n",
    "from rsgc.GeneCompatibility.gc import gc_enzyme as gce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in parameters for RetSynth Run \n",
    "#### Go through the parameters and make sure you specify a path to a target file (list of targets and host organisms, targets_path option as well as generate a database (generate_database & generate_database_constraints) or use pre-constructed database with database and database_constraint options. If you are generating a new constraint file make sure to read the documentation and specify necessary database construction parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Parameters for RetSynth Run \n",
    "targets_path=\"testtargets.txt\"\n",
    "output_path=\"Results/\"\n",
    "output_html=True\n",
    "output_xlsx_format=False\n",
    "processors=4\n",
    "start_compounds=None\n",
    "verbose=False\n",
    "\n",
    "#database parameters\n",
    "generate_database=\"database.db\"\n",
    "generate_database_constraints=\"database.constraints\"\n",
    "database=False\n",
    "database_constraints=False\n",
    "inchidb=True\n",
    "\n",
    "#database construction parameters\n",
    "patric_models=True\n",
    "patric_username=None\n",
    "patric_password=None\n",
    "patric_reaction_type=\"bio\"\n",
    "patric_media=\"Carbon-D-Glucose\"\n",
    "patric_sbml_output=False\n",
    "patricfile='PATRIC_genome_complete.csv'\n",
    "patric_models_already_built=False\n",
    "metacyc=True\n",
    "metacyc_addition=\"\"\n",
    "metacyc_reaction_type=\"bio\"\n",
    "kegg=False\n",
    "kegg_reaction_type=\"bio\"\n",
    "kegg_organism_type=\"bacteria\"\n",
    "kegg_number_of_organisms=\"all\"\n",
    "kegg_number_of_organism_pathway=\"all\"\n",
    "atlas=False\n",
    "atlas_dump_directory=None\n",
    "atlas_reaction_type=\"bio\"\n",
    "mine=False\n",
    "mine_dump_directory=None\n",
    "mine_reaction_type=True\n",
    "SPRESI=False\n",
    "spresi_dump_directory=None\n",
    "spresi_reaction_type=\"chem\"\n",
    "user_rxns_2_database=False\n",
    "user_rxns_2_database_type=\"bio\"\n",
    "\n",
    "#Flux balance analysis \n",
    "flux_balance_analysis=True\n",
    "media_for_FBA=\"Carbon-D-Glucose\"\n",
    "knockouts=False\n",
    "\n",
    "#Other parameters for RetSynth\n",
    "limit_reactions=10\n",
    "limit_cycles='None'\n",
    "solver_time_limit=30\n",
    "evaluate_reactions=\"all\" \n",
    "k_number_of_paths=0\n",
    "multiple_solutions=str(True)\n",
    "cycles=str(True)\n",
    "run_tanimoto_threshold=False\n",
    "tanimoto_threshold=1\n",
    "figures_chemdraw=False\n",
    "figures_graphviz=True\n",
    "show_rxn_info=False\n",
    "images=True\n",
    "timer_output=False\n",
    "\n",
    "##Gene compatibility parameters\n",
    "gene_compatability=True\n",
    "cai_threshold=0.23\n",
    "user_cai_table=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in necessary functions for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load necessary functions needed for downstream processing\n",
    "def get_compartmentID_from_db(DB, compartment):\n",
    "    '''Retrieves specified compartment ID'''\n",
    "    compartment = compartment.lower()\n",
    "    compartmentID_array = DB.get_compartment(compartment)\n",
    "    if compartmentID_array is None or len(compartmentID_array) == 0 or compartmentID_array[0] == '':\n",
    "        print ('WARNING: Could not retrieve a compartment ID from the database')\n",
    "        if compartment == 'cytosol':\n",
    "            compartmentID = 'c0'\n",
    "        elif compartment == 'extracellular':\n",
    "            compartmentID = 'e0'\n",
    "        else:\n",
    "            compartmentID = 'c0'\n",
    "    else:\n",
    "        compartmentID = compartmentID_array[0]\n",
    "    return (compartmentID)\n",
    "\n",
    "def get_new_temp_imgs_folder(PATH, count):\n",
    "    '''Check if folder to store images is already present if so new temp folder is made'''\n",
    "    count+=1\n",
    "    try:\n",
    "        os.mkdir(PATH+'/temp_imgs_'+str(count))\n",
    "        return PATH+'/temp_imgs_'+str(count)\n",
    "    except OSError:\n",
    "        PATH_NEW = get_new_temp_imgs_folder(PATH, count)\n",
    "        return PATH_NEW\n",
    "\n",
    "def _specific_target(target_id):\n",
    "    '''Determines if there was a specified organism'''\n",
    "\n",
    "    if target_id in ['', 'NA', 'N/A']:\n",
    "        return False\n",
    "\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def targets_missing(targets,database):\n",
    "    '''Check if targets are missing from the database'''\n",
    "    DB = Q.Connector(database)\n",
    "    all_compounds = DB.get_all_compounds()\n",
    "\n",
    "    for t in targets:\n",
    "        if t[0] not in all_compounds:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def run_flux_balance_analysis(target_info, ex_info, incpds_active,\n",
    "                              inrxns, media, ko,\n",
    "                              output, DB, verbose):\n",
    "    '''\n",
    "    Run flux balance analysis on target organism with added reactions\n",
    "    necessary to produce target compound\n",
    "    '''\n",
    "    fba = bm.BuildModel(target_info[2], incpds_active, inrxns, DB, verbose, media)\n",
    "    opt_fba = ot.OptimizeTarget(target_info[0], target_info[2], fba.model, ex_info.temp_rxns,\n",
    "                                ex_info.temp_exmets, fba.compounds_dict, incpds_active,\n",
    "                                inrxns, DB, verbose, ko)\n",
    "    # print (opt_fba.fbasol.fluxes)\n",
    "    comparisonresults = cr.Compare(target_info[0], fba.solution, opt_fba.fbasol,\n",
    "                                   ex_info.temp_rxns, DB)\n",
    "    output.output_FBA(target_info, fba.solution, opt_fba, comparisonresults, ex_info.temp_rxns)\n",
    "    output.output_theoretical_yield(target_info[0], target_info[2], opt_fba.fbasol,\n",
    "                                    opt_fba.compounds_dict)\n",
    "\n",
    "    if ko:\n",
    "\n",
    "        output.output_essential_reactions(target_info[0], target_info[2], opt_fba.essentialrxns)\n",
    "        comparisonKOresults = crko.CompareKO(target_info[0], opt_fba.compounds_dict, opt_fba.fbasol,\n",
    "                                             opt_fba.KOsolutions, ex_info.temp_rxns, DB)\n",
    "        output.output_FBA_KOs(target_info, opt_fba.fbasol, opt_fba.compounds_dict, comparisonKOresults, ex_info.temp_rxns)\n",
    "\n",
    "    return opt_fba\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate folder to store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate new output folder\n",
    "try:\n",
    "    verbose_print(verbose, \"STATUS: generating output folder \"+output_path)\n",
    "    os.mkdir(output_path)\n",
    "except:\n",
    "    verbose_print(verbose, \"STATUS: output folder already exists \"+output_path)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check and make sure all necessary arguments/options are specified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check arguments for errors\n",
    "def check_arguments():\n",
    "        '''Checks and makes sure all required arguments are provided'''\n",
    "        if knockouts and not flux_balance_analysis:\n",
    "            raise ValueError('--knockouts option requires that \\\n",
    "                        --flux_balance_analysis option be also specified')\n",
    "\n",
    "        if metacyc and not metacyc_addition:\n",
    "            raise ValueError('--metacyc requires use of parameters metacyc_addition')        \n",
    "\n",
    "        if atlas and not atlas_dump_directory:\n",
    "            raise ValueError('--atlas requires use of --atlas_dump_directory')\n",
    "\n",
    "        if SPRESI and not spresi_dump_directory:\n",
    "            raise ValueError('--SPRESI requires use of --spresi_dump_directory')\n",
    "\n",
    "        if mine and not mine_dump_directory:\n",
    "            raise ValueError('--mine requires use of --mine_dump_directory')\n",
    "\n",
    "        if patric_models and not patric_password:\n",
    "            raise ValueError('--patric_models requires options --patric_models, --patric_username, and --patric_password be specified')\n",
    "        \n",
    "        if patric_models and not patric_username:\n",
    "            raise ValueError('--patric_models requires options --patric_models, --patric_username, and --patric_password be specified')\n",
    "        \n",
    "        if patric_username and not patric_password:\n",
    "            raise ValueError('--patric_username requires options --patric_models, --patric_username, and --patric_password be specified')\n",
    "\n",
    "        if not patric_models and patric_models_already_built:\n",
    "            raise ValueError('--previously_built_patric_models requires options --patric_models, --patric_username, and --patric_password be specified')\n",
    "\n",
    "        if start_compounds and flux_balance_analysis:\n",
    "            raise ValueError('Flux balance cannot be performed on a set of starting compounds\\\n",
    "                        would need to use an organisms metabolism to simulate flux')\n",
    "\n",
    "        if not multiple_solutions and k_number_of_paths:\n",
    "            raise ValueError('Cannot find k_number_of_paths correctly \\\n",
    "                        without finding all multiple_solutions')\n",
    "        if not targets_path:\n",
    "            raise ValueError('Requires an input file of target compounds')\n",
    "#Run check\n",
    "check_arguments()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build or load database depending on whether you specified the generate_database option or database option "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Database\n",
    "def retrieve_database_info(database, generate_database):\n",
    "    '''\n",
    "    Generates database or uses previously generated database.\n",
    "    Can also add metacyc database to a Kbase metabolic database\n",
    "    '''\n",
    "    if generate_database:\n",
    "        '''\n",
    "        Generate a database\n",
    "        '''\n",
    "        init_db.Createdb(generate_database)\n",
    "        database = generate_database\n",
    "        new_db = True\n",
    "        print (database)\n",
    "\n",
    "    elif database:\n",
    "        new_db = False\n",
    "        database = database\n",
    "\n",
    "    if patric_models:\n",
    "        #Add PATRIC repository to database\n",
    "        bms.BuildModelSeed(username=patric_username, password=patric_password, rxntype=patric_reaction_type,\n",
    "                            inchidb=inchidb, DBpath=generate_database, output_folder=output_path, media=patric_media, \n",
    "                            patricfile=patricfile, newdb=new_db, sbml_output=patric_sbml_output,\n",
    "                            previously_built_patric_models=patric_models_already_built)\n",
    "\n",
    "    if metacyc:\n",
    "        #Add metacyc repository to database\n",
    "        bmcdb.Translate(database, metacyc_addition,\n",
    "                        inchidb, metacyc_reaction_type, verbose)\n",
    "\n",
    "    if kegg and (patric_models or kbase or metacyc):\n",
    "        #Add kegg repository database\n",
    "        BKD = bkeggdb.CompileKEGGIntoDB(database, kegg_organism_type,\n",
    "                                        inchidb, processors, kegg_number_of_organisms,\n",
    "                                        kegg_number_of_organism_pathways,\n",
    "                                        kegg_reaction_type, True)\n",
    "\n",
    "    elif kegg and not kbase and not patric_models and not metacyc:\n",
    "        #Add kegg repository database\n",
    "        print ('STATUS: Add only KEGG to RetSynth database')\n",
    "        BKD = bkeggdb.CompileKEGGIntoDB(database, kegg_organism_type,\n",
    "                                        inchidb, processors,\n",
    "                                        kegg_number_of_organisms, kegg_number_of_organism_pathways,\n",
    "                                        kegg_reaction_type, False)\n",
    "\n",
    "    if user_rxns_2_database:\n",
    "        #Add user identified reactions\n",
    "        burdb.AddUserRxns2DB(database, user_rxns_2_database,\n",
    "                            model_id='UserAdded', rxntype=user_rxns_2_database_type)\n",
    "    if SPRESI:\n",
    "        #Translate synthetic rdf files from SPRESI into database\n",
    "        DB = Q.Connector(database)\n",
    "        cytosol_compartmentID = get_compartmentID_from_db(DB, 'cytosol')\n",
    "        bspresidb.RDF_Reader(spresi_dump_directory,\n",
    "                            database,\n",
    "                            spresi_reaction_type,\n",
    "                            cytosol_compartmentID, processors)\n",
    "\n",
    "    if mine:\n",
    "        #Add MINE repository to database\n",
    "        bminedb.BuildMINEdb(mine_dump_directory, database,\n",
    "                            inchidb, mine_reaction_type)\n",
    "\n",
    "    if atlas:\n",
    "        #Add ATLAS repository to database\n",
    "        batlasdb.build_atlas(atlas_dump_directory, database, inchidb,\n",
    "                                processors, atlas_reaction_type)\n",
    "\n",
    "    if inchidb and (patric_models or metacyc or kegg or SPRESI or mine or atlas):\n",
    "        #Remove duplicate compounds from database\n",
    "        rdc.OverlappingCpdIDs(database)\n",
    "\n",
    "    ##IF DATABASE IS NOT SPECIFIED USE DEFUALT DATABASE IN ./ConstructedDatabases FOLDER##\n",
    "    if not generate_database and not database:\n",
    "\n",
    "        if media_for_FBA == 'Carbon-D-Glucose':\n",
    "\n",
    "            print ('WARNING: No database specified using pre constructed database with media {}'.format(media_for_FBA))\n",
    "\n",
    "            database = PATH+'/ConstructedDatabases/DBINCHIECOLIDH1_GL_MC.db'\n",
    "            DB = Q.Connector(database)\n",
    "\n",
    "        elif media_for_FBA == 'Complete':\n",
    "\n",
    "            print ('WARNING: No database specified using pre constructed database with media {}'.format(media_for_FBA))\n",
    "\n",
    "            database = PATH+'/ConstructedDatabases/DBINCHIECOLIDH1_CP_MC_cas_SPRESI_reduced1x.db'            \n",
    "\n",
    "            DB = Q.Connector(database)\n",
    "    else:\n",
    "        DB = Q.Connector(database)\n",
    "\n",
    "    ###GET TYPE OF REACTIONS TO BE USED IN THE ANALYSIS SO CORRECT CONTRAINT FILE IS GENERATED##\n",
    "    print (database)\n",
    "    allcpds = DB.get_all_compounds()\n",
    "    if evaluate_reactions == 'all':\n",
    "        allrxns = DB.get_all_reactions()\n",
    "    elif evaluate_reactions == 'bio':\n",
    "        allrxns = DB.get_reactions_based_on_type('bio')\n",
    "    elif evaluate_reactions == 'chem':\n",
    "        allrxns = DB.get_reactions_based_on_type('chem')\n",
    "    return(allcpds, allrxns, database)\n",
    "\n",
    "#Run function\n",
    "\n",
    "all_db_compounds, all_db_reactions, database = retrieve_database_info(database, generate_database)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in targets from target_path as well build and load constraint object which is used to identify pathways for targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in target file and constraints files\n",
    "def read_in_and_generate_output_files(database, targets_path, run_tanimoto_threshold):\n",
    "    '''Read in target input file and generate output files'''\n",
    "    DB = Q.Connector(database)\n",
    "    R = rt.Readfile(targets_path, DB, inchidb)\n",
    "    if not R.targets:\n",
    "        raise ValueError('ERROR:\\tNo targets, try different compounds')\n",
    "    try:\n",
    "        verbose_print(verbose, \"STATUS: generating output folder \"+output_path)\n",
    "        os.mkdir(output_path)\n",
    "    except:\n",
    "        verbose_print(verbose, \"STATUS: output folder already exists \"+output_path)\n",
    "        pass\n",
    "    DB_missing_targets = targets_missing(R.targets, database)\n",
    "    if DB_missing_targets:\n",
    "        run_tanimoto_threshold = True\n",
    "        verbose_print(verbose, 'STATUS:\\tTarget not found in database. Trying to find structurally similar compounds')\n",
    "    temp_imgs_PATH = get_new_temp_imgs_folder(output_path, 0)\n",
    "    OUTPUT = go.Output(DB, output_path, verbose, flux_balance_analysis, knockouts, timer_output, GC=gene_compatability)\n",
    "    if run_tanimoto_threshold:\n",
    "        verbose_print(verbose, 'STATUS:\\t{} tanimoto threshold being used'.format(float(tanimoto_threshold)*100))\n",
    "        cytosol_compartmentID = get_compartmentID_from_db(DB, 'cytosol')\n",
    "        extracell_compartmentID = get_compartmentID_from_db(DB, 'extracellular')\n",
    "        SIM = ss.TanimotoStructureSimilarity(R.targets, DB.get_all_compounds(),\n",
    "                                             cytosol_compartmentID, extracell_compartmentID,\n",
    "                                             verbose, tanimoto_threshold)\n",
    "        OUTPUT.output_final_targets(SIM.finaltargets, tanimoto_threshold)\n",
    "        if DB_missing_targets and len(SIM.finaltargets) == 1:\n",
    "            verbose_print(verbose, 'STATUS:\\tNo structurally similar compounds available with threshold %.2f' % tanimoto_threshold)\n",
    "            return ([], R.ignorerxns, OUTPUT, temp_imgs_PATH)\n",
    "        else:\n",
    "          return(SIM.finaltargets, R.ignorerxns, OUTPUT, temp_imgs_PATH)\n",
    "    else:\n",
    "        return(R.targets, R.ignorerxns, OUTPUT, temp_imgs_PATH)\n",
    "\n",
    "def retrieve_constraints(allrxns, allcpds, ignore_reactions, database):\n",
    "    '''\n",
    "    Generates database constraints or uses previously generated\n",
    "    database constraints (.constraints) file\n",
    "    '''\n",
    "    DB = Q.Connector(database)\n",
    "\n",
    "    def store_constraint_file(filename, LP):\n",
    "        '''store generated constraints into .constraints'''\n",
    "        \n",
    "        print ('STATUS:\\tDumping newly generated variables...')\n",
    "\n",
    "        with open(filename, 'wb') as fout1:\n",
    "            \n",
    "            print ('STATUS:\\tDumping LP structure...')\n",
    "            pickle.dump(LP.lp, fout1)\n",
    "            \n",
    "            print ('STATUS:\\tDumping all compounds...')\n",
    "            pickle.dump(LP.allcpds, fout1)\n",
    "\n",
    "            print ('STATUS:\\tDumping all reaction variables...')\n",
    "            pickle.dump(LP.variables, fout1)\n",
    "\n",
    "            print ('STATUS:\\tDumping all reactions 1...')\n",
    "            pickle.dump(LP.allrxnsrev_dict_rev, fout1)\n",
    "  \n",
    "            print ('STATUS:\\tDumping all reactions 2...')\n",
    "            pickle.dump(LP.allrxnsrev_dict, fout1)\n",
    "\n",
    "            print ('STATUS:\\tDumping all reactions 3...')\n",
    "            pickle.dump(LP.allrxnsrev, fout1)\n",
    "\n",
    "    def unload_constraint_file(filename):\n",
    "        '''unload constraints from a .constraints'''\n",
    "\n",
    "        print ('STATUS:\\tLoading pre-stored variables...')\n",
    "\n",
    "        with open(filename, 'rb') as fin1:\n",
    "            \n",
    "            print ('STATUS:\\tLoading LP structure...')\n",
    "            lp = pickle.load(fin1)\n",
    "\n",
    "            print ('STATUS:\\tLoading all compounds...')\n",
    "            allcompounds4matrix = pickle.load(fin1)\n",
    "\n",
    "            print ('STATUS:\\tLoading all reaction variables...')\n",
    "            variables = pickle.load(fin1)\n",
    "\n",
    "            print ('STATUS:\\tLoading all reactions 1...')\n",
    "            allrxnsrev_dict_rev = pickle.load(fin1)\n",
    "\n",
    "            print ('STATUS:\\tLoading all reactions 2...')\n",
    "            allrxnsrev_dict = pickle.load(fin1)\n",
    "\n",
    "            print ('STATUS:\\tLoading all reactions 3...')\n",
    "            allrxnsrev = pickle.load(fin1)\n",
    "\n",
    "        return (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev)\n",
    "\n",
    "    def load_preconstructed_constraint_files(media, mediatype, args):\n",
    "        '''load defualt .constraint files'''\n",
    "\n",
    "        print ('WARNING:\\tNo database constraint file specified using pre constructed database constraint file for database')\n",
    "        if evaluate_reactions =='all':\n",
    "\n",
    "            (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev) = unload_constraint_file(PATH+'/ConstructedDatabases/' + DEFAULT_DB_NAME + '.constraints')\n",
    "            \n",
    "            return (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev)\n",
    "\n",
    "        elif evaluate_reactions =='chem':\n",
    "\n",
    "            (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev) = unload_constraint_file(PATH+'/ConstructedDatabases/' + DEFAULT_DB_NAME + '_chem.constraints')\n",
    "            \n",
    "            return (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev)  \n",
    "\n",
    "        elif evaluate_reactions =='bio':\n",
    "\n",
    "            (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev) = unload_constraint_file(PATH+'/ConstructedDatabases/' + DEFAULT_DB_NAME + '_bio.constraints')\n",
    "            \n",
    "            return (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev)  \n",
    "\n",
    "\n",
    "\n",
    "    ###RETRIEVE SPECIFIED BY USER CONSTRAINTS###\n",
    "    if generate_database_constraints:\n",
    "        LP = co.ConstructInitialLP(allrxns, allcpds, DB, ignore_reactions)\n",
    "        store_constraint_file(generate_database_constraints, LP)\n",
    "\n",
    "    elif database_constraints:\n",
    "        (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev) = unload_constraint_file(database_constraints) \n",
    "        LP = co.ConstructInitialLP(allrxns, allcompounds4matrix, DB,\n",
    "                                   ignore_reactions, lp, variables, allrxnsrev_dict_rev,\n",
    "                                   allrxnsrev_dict, allrxnsrev)\n",
    "    else:\n",
    "        if media_for_FBA=='Carbon-D-Glucose':\n",
    "            \n",
    "            (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev) = load_preconstructed_constraint_files(media_for_FBA, 'GL', args)\n",
    "        \n",
    "        elif media_for_FBA=='Complete':\n",
    "            \n",
    "            (lp, allcompounds4matrix, variables, allrxnsrev_dict_rev, allrxnsrev_dict, allrxnsrev) = load_preconstructed_constraint_files(media_for_FBA, 'CP', args)\n",
    "        \n",
    "            LP = co.ConstructInitialLP(allrxns, allcompounds4matrix, DB,\n",
    "                                       ignore_reactions, lp, variables, allrxnsrev_dict_rev,\n",
    "                                       allrxnsrev_dict, allrxnsrev)\n",
    "        else: \n",
    "            print ('ERROR:\\tNo identified pre constraint file...stopping run')\n",
    "\n",
    "    return LP\n",
    "\n",
    "def construct_and_run_integerprogram(targets, output, database):\n",
    "    '''\n",
    "    Constructs ILP and solves it identifying shortest path to the target\n",
    "    '''\n",
    "\n",
    "    DB = Q.Connector(database)\n",
    "\n",
    "    if timer_output:\n",
    "\n",
    "        IP = ip_pulp.IntergerProgram(DB, limit_reactions,\n",
    "                                    limit_cycles, k_number_of_paths,\n",
    "                                    cycles, verbose, solver_time_limit, output)\n",
    "    else:\n",
    "\n",
    "        IP = ip_pulp.IntergerProgram(DB, limit_reactions,\n",
    "                                    limit_cycles, k_number_of_paths,\n",
    "                                    cycles, verbose, solver_time_limit, timer_output)\n",
    "\n",
    "    return IP\n",
    "\n",
    "#Run functions\n",
    "targets, ignore_reactions, output, temp_imgs_PATH = read_in_and_generate_output_files(database, targets_path, run_tanimoto_threshold)\n",
    "LP = retrieve_constraints(all_db_reactions, all_db_compounds, ignore_reactions, database)\n",
    "IP = construct_and_run_integerprogram(targets, output, database)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find pathways for target using the built or loaded database and constraint object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find pathway for targets \n",
    "def retrieve_shortestpath(target_info, IP, LP, database, output, temp_imgs_PATH, timer_output, media_for_FBA, \n",
    "                          flux_balance_analysis, knockouts, images, figures_graphviz, figures_chemdraw, evaluate_reactions,\n",
    "                          show_rxn_info, output_path, multiple_solutions, start_compounds, gene_compatability,\n",
    "                          orgs_gbs, gbs_orgs, RGC, keggorganisms_ids, output_genecompdb, verbose):\n",
    "    '''Retrieve the shortest path for target organism'''\n",
    "\n",
    "    start = timer()\n",
    "    DB = Q.Connector(database)\n",
    "    SP = None\n",
    "    ranktype = None\n",
    "\n",
    "    verbose_print(verbose, \"STATUS: getting path for {}\".format(target_info))\n",
    "\n",
    "    if images == False:\n",
    "        _images = False\n",
    "    else:\n",
    "        _images = True\n",
    "\n",
    "    if not _specific_target(target_info[2]) and not start_compounds:\n",
    "        print ('WARNING: No organism given therefore target {} compound will be skipped ... '.format(target_info[0]))\n",
    "\n",
    "    else:\n",
    "\n",
    "        if start_compounds:\n",
    "\n",
    "            incpds_active = rtsc.readfile_startcompounds(start_compounds)\n",
    "            inrxns_active = []\n",
    "\n",
    "        else:\n",
    "\n",
    "            incpds_active = DB.get_compounds_in_model(target_info[2])\n",
    "            inrxns_active = DB.get_reactions_in_model(target_info[2])\n",
    "\n",
    "        if target_info[0] in incpds_active: #Check if compound exists in organism\n",
    "\n",
    "            output.output_compound_natively_present_in_target_organism(target_info)\n",
    "\n",
    "        else:\n",
    "            optimal_pathways = IP.run_glpk(LP, incpds_active, inrxns_active, target_info[0],\n",
    "                                           multiplesolutions=multiple_solutions)\n",
    "            if optimal_pathways:                    \n",
    "                uniq_externalrxns = []\n",
    "                for path in optimal_pathways:\n",
    "                    path_org = []\n",
    "                    for rxn in path:\n",
    "                        rxn = re.sub('_F$', '', rxn)\n",
    "                        rxn = re.sub('_R$', '', rxn)\n",
    "                        path_org.append(rxn)\n",
    "                    uniq_externalrxns.append(list(set(path_org) - set(inrxns_active)))\n",
    "\n",
    "                ex_info = ei.Extract_Information(optimal_pathways, incpds_active, inrxns_active, DB)\n",
    "                output.output_shortest_paths(target_info, ex_info.temp_rxns)\n",
    "\n",
    "                R = rf.ReactionFiles(output_path, DB, ex_info.temp_rxns,\n",
    "                                 target_info[0], target_info[2], incpds_active)\n",
    "\n",
    "                output.output_raw_solutions(target_info[0], target_info[2], R.ordered_paths,\n",
    "                                            ex_info.temp_rxns, ex_info.temp_external, incpds_active)\n",
    "\n",
    "                if flux_balance_analysis:\n",
    "                    opt_fba = run_flux_balance_analysis(target_info, ex_info,\n",
    "                                                        incpds_active, inrxns_active,\n",
    "                                                        media_for_FBA, knockouts,\n",
    "                                                        output, DB, verbose)\n",
    "\n",
    "                    R.generate_cdxml_files(RP=None, ranktype=None, fba_fluxes=opt_fba.fbasol.fluxes, show_rxn_info=show_rxn_info)\n",
    "                    \n",
    "                    if figures_graphviz:\n",
    "\n",
    "                        G = spgd.GraphDot(DB, output_path, incpds_active, inrxns_active,\n",
    "                                          temp_imgs_PATH, opt_fba.fbasol.fluxes)\n",
    "                        G.sc_graph(target_info[0], target_info[2], ex_info.temp_rxns, _images)\n",
    "\n",
    "                elif not flux_balance_analysis:\n",
    "                    R.generate_cdxml_files()\n",
    "\n",
    "                    if figures_graphviz:\n",
    "                        G = spgd.GraphDot(DB, output_path, incpds_active, inrxns_active, temp_imgs_PATH)\n",
    "                        G.sc_graph(target_info[0], target_info[2], ex_info.temp_rxns, _images)\n",
    "\n",
    "                if gene_compatability:\n",
    "                    verbose_print(verbose, 'STATUS:\\tOptimizing gene sequences for optimal pathway reaction enzymes...')\n",
    "                    enzymes = list(R.enzyme_set)\n",
    "                    if len(enzymes) != 0:\n",
    "                        output.generate_gc_directory()\n",
    "                        for enzyme in enzymes:\n",
    "                            if os.path.isfile(os.path.join(output.GC_output_path, \"geneseqs_{}_{}.txt\".format(enzyme, target_info[2]))):\n",
    "                                print (\"STATUS: already have sequence information for {} in {}\".format(enzyme, target_info[2]))\n",
    "                            else:\n",
    "                                gce(enzyme, orgs_gbs, gbs_orgs, target_info[2], RGC, keggorganisms_ids, output_genecompdb,\n",
    "                                    output_directory=output.GC_output_path, user_cai_table=user_cai_table,\n",
    "                                    cai_optimal_threshold=cai_threshold)\n",
    "                    else:\n",
    "                        verbose_print(verbose, 'STATUS:')\n",
    "\n",
    "            else:\n",
    "                output.output_shortest_paths(target_info, [])\n",
    "                if flux_balance_analysis:\n",
    "                    verbose_print(verbose, 'WARNING:\\tNo optimal path for %s in species %s therefore no flux balance will be performed' % (target_info[0], target_info[2]))\n",
    "    end = timer()\n",
    "    end = timer()\n",
    "\n",
    "    if timer_output:\n",
    "\n",
    "        output.output_timer('Time to find all paths for {}\\t{}\\t{}\\n'.format(target_info[0], (end-start), (end-start)/60))\n",
    "\n",
    "    verbose_print(verbose, \"Time to find all paths for \"+str(target_info[0])+' '+str(end - start))\n",
    "\n",
    "\n",
    "##Run retrieve_shortestpath\n",
    "if gene_compatability:\n",
    "    orgs_gbs, gbs_orgs, R, keggorganisms_ids, output_genecompdb = gc(database, \n",
    "                                                                     output_directory=output_path,\n",
    "                                                                     default_db='')\n",
    "else:\n",
    "    orgs_gbs=False\n",
    "    gbs_orgs=False\n",
    "    R=False\n",
    "    keggorganisms_ids=False\n",
    "    output_genecompdb=False\n",
    "\n",
    "args_targets = [targets[i:i+processors]\n",
    "              for i in range(0, len(targets), processors)]\n",
    "for targets in args_targets:\n",
    "    processes = []\n",
    "    for target in targets:\n",
    "        processes.append(Process(target=retrieve_shortestpath, args=(target, IP, LP, database, output,\n",
    "                                                    temp_imgs_PATH, timer_output, media_for_FBA,\n",
    "                                                    flux_balance_analysis, knockouts, images,\n",
    "                                                    figures_graphviz, figures_chemdraw, evaluate_reactions, show_rxn_info,\n",
    "                                                    output_path, multiple_solutions, start_compounds, gene_compatability,\n",
    "                                                    orgs_gbs, gbs_orgs, R, keggorganisms_ids, output_genecompdb,\n",
    "                                                    verbose)))\n",
    "\n",
    "    for p in processes:        \n",
    "        p.start()\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "\n",
    "if output_xlsx_format:\n",
    "    output.convert_output_2_xlsx()\n",
    "\n",
    "if output_html:\n",
    "    print(\"STATUS: writing html file\")\n",
    "    gh.HtmlOutput(len(targets), output_path, flux_balance_analysis, figures_graphviz, database, output_path+\"/Results.html\")\n",
    "\n",
    "'''Remove all temporary images'''\n",
    "shutil.rmtree(temp_imgs_PATH)\n",
    "\n",
    "'''Removes all dot files if they exist'''\n",
    "for filename in glob.glob(output_path+\"/solution_figures/*.dot\"):\n",
    "    os.remove(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in html file of results, only run this if option output_html is set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HTML(output_path+\"/Results.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}